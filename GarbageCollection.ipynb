{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fed57ba-d278-4b36-bfb2-a1c0734a41c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Layer\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Layer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers, optimizers, callbacks\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.applications import EfficientNetV2B2\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import gradio as gr\n",
    "from tensorflow.keras.layers import Rescaling, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fbd80a-9e30-4dd0-ae50-da77851a92a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir= r\"C:\\Users\\keert\\Downloads\\AICET_FINAL_GarbageCollection\\archive\\TrashType_Image_Dataset\"\n",
    "\n",
    "image_size = (124, 124)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6771d99-36ca-41c1-bee4-1731c3083419",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "\n",
    "dataset_dir,\n",
    "\n",
    "validation_split=0.2,\n",
    "\n",
    "subset=\"training\",\n",
    "\n",
    "seed=seed,\n",
    "\n",
    "shuffle = True,\n",
    "\n",
    "image_size=image_size,\n",
    "\n",
    "batch_size=batch_size\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ca5c77-f4bc-4295-be48-6a3257aa9e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "\n",
    "dataset_dir,\n",
    "\n",
    "validation_split=0.2,\n",
    "\n",
    "subset=\"validation\",\n",
    "\n",
    "seed=seed,\n",
    "\n",
    "shuffle = True,\n",
    "\n",
    "image_size=image_size,\n",
    "\n",
    "batch_size=batch_size\n",
    "\n",
    ")\n",
    "\n",
    "val_class= val_ds.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c780f1-60b0-4ad2-a147-626fa6ae0536",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_batches = tf.data.experimental.cardinality(val_ds)\n",
    "test_ds = val_ds.take(val_batches // 2)\n",
    "val_dat = val_ds.skip(val_batches // 2)\n",
    "\n",
    "test_ds_eval = test_ds.cache().prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0a9729-66da-46f3-b2bc-2d48a85bfcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_ds.class_names)\n",
    "\n",
    "print(val_class)\n",
    "\n",
    "print(len(train_ds.class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f5b7a9-dabb-4641-a269-d7b6c65e23c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(12):\n",
    "        ax = plt.subplot(4, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(train_ds.class_names[labels[i]])\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984ec3b6-1277-4e78-858d-cb1b1c6ac3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_distribution(dataset, class_names):\n",
    "    total = 0\n",
    "    counts = {name: 0 for name in class_names}\n",
    "\n",
    "    for _, labels in dataset:\n",
    "        for label in labels.numpy():\n",
    "            class_name = class_names[label]\n",
    "            counts[class_name] += 1\n",
    "            total += 1\n",
    "\n",
    "    for k in counts:\n",
    "        counts[k] = round((counts[k] / total) * 100, 2)  # Convert to percentage\n",
    "\n",
    "    return counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937c8b62-0690-413f-8ded-95dc60f5aeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot class distribution\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def simple_bar_plot(dist, title):\n",
    "    plt.bar(dist.keys(), dist.values(), color='cornflowerblue')\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Percentage (%)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylim(0, 100)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475fbe3f-485a-448e-85f2-9902534289be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "\n",
    "# Helper to count class distribution in dataset\n",
    "def get_distribution(dataset, class_names):\n",
    "    counts = {k: 0 for k in class_names}\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in dataset:\n",
    "        for label in labels:\n",
    "            class_name = class_names[int(label)]\n",
    "            counts[class_name] += 1\n",
    "            total += 1\n",
    "\n",
    "    if total == 0:\n",
    "        return counts  # avoid ZeroDivisionError\n",
    "\n",
    "    for k in counts:\n",
    "        counts[k] = round((counts[k] / total) * 100, 2)\n",
    "\n",
    "    return counts\n",
    "\n",
    "# Compute distributions\n",
    "train_dist = get_distribution(train_ds, class_names)\n",
    "val_dist = get_distribution(val_ds, class_names)\n",
    "test_dist = get_distribution(test_ds, class_names)\n",
    "\n",
    "# Compute overall distribution from train + val\n",
    "overall_dist = {}\n",
    "for k in class_names:\n",
    "    overall_dist[k] = round((train_dist.get(k, 0) + val_dist.get(k, 0)) / 2, 2)\n",
    "\n",
    "# Print results\n",
    "print(\"Train Distribution:\", train_dist)\n",
    "print(\"Validation Distribution:\", val_dist)\n",
    "print(\"Test Distribution:\", test_dist)\n",
    "print(\"Overall Distribution (Train + Val Avg):\", overall_dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fc15a8-eaea-42d2-ad81-cb9d68a842e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Count class occurrences and prepare label list\n",
    "class_counts = {i: 0 for i in range(len(class_names))}\n",
    "all_labels = []\n",
    "\n",
    "for images, labels in train_ds:\n",
    "    for label in labels.numpy():\n",
    "        if isinstance(label, np.ndarray):  # handle one-hot encoded case\n",
    "            label = np.argmax(label)\n",
    "        class_counts[label] += 1\n",
    "        all_labels.append(label)\n",
    "\n",
    "# Compute class weights\n",
    "class_weights_array = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(all_labels),  # use actual labels present in the data\n",
    "    y=all_labels\n",
    ")\n",
    "\n",
    "# Create dictionary mapping class index to weight\n",
    "class_weights = {i: w for i, w in zip(np.unique(all_labels), class_weights_array)}\n",
    "\n",
    "# Optional: print for review\n",
    "print(\"Class counts:\", class_counts)\n",
    "print(\"Class weights:\", class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3ee41a-8ec1-41ac-b98c-0f09b3c5085b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Define data augmentation pipeline\n",
    "data_augmentation = Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "    layers.RandomContrast(0.1),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ed3e60-98d4-4042-9e6b-05c3dfa2e5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import EfficientNetV2B2\n",
    "\n",
    "base_model = EfficientNetV2B2(\n",
    "    include_top=False,\n",
    "    input_shape=(124, 124, 3),\n",
    "    include_preprocessing=True,\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "# Freeze early layers (to retain general pretrained features)\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:100]:  # Adjust as needed\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307809ff-2772-4a46-b2b8-9d2cea73017e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential, layers\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "model = Sequential([\n",
    "    layers.Input(shape=(124, 124, 3)),\n",
    "    data_augmentation,\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(6, activation='softmax')  # Assuming 6 classes\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02267b17-6730-473f-a0cd-84367c85550b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122d3d01-77d8-405f-ba8e-2cd9ab63a979",
   "metadata": {},
   "outputs": [],
   "source": [
    "early = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f413b32-6cd6-496f-8405-558b47b8caf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix class_weights to reindex from 0\n",
    "label_mapping = {label: idx for idx, label in enumerate(sorted(set(all_labels)))}\n",
    "mapped_labels = [label_mapping[label] for label in all_labels]\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "class_weights_array = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.arange(len(label_mapping)),\n",
    "    y=mapped_labels\n",
    ")\n",
    "\n",
    "class_weights = {i: w for i, w in enumerate(class_weights_array)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9604157d-bcf2-44fd-88d4-b879e558e5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b567eb-ee22-4b0e-a7f4-e8f6a253da66",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e657aa97-ae2e-4ecc-a850-c1aadb7b588d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(test_ds_eval)\n",
    "\n",
    "print(f'Test accuracy is {accuracy:.4f}, Test loss is {loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e4b30a-f83d-446e-beb1-5e178abc60ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Extract true labels from all batches\n",
    "y_true = np.concatenate([y.numpy() for x, y in test_ds_eval], axis=0)\n",
    "\n",
    "# Get predictions as probabilities\n",
    "y_pred_probs = model.predict(test_ds_eval)\n",
    "\n",
    "# Convert probabilities to predicted class indices\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5370a2-9d3f-457e-ab9f-2f8ab884b0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d',\n",
    "            xticklabels=class_names,\n",
    "            yticklabels=class_names,\n",
    "            cmap='Blues')\n",
    "\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea198f74-cef6-4121-a2fd-9048581c267a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract class names from the training dataset\n",
    "class_names = train_ds.class_names  \n",
    "\n",
    "# Take one batch of images and labels from the test dataset for evaluation\n",
    "for images, labels in test_ds_eval.take(1):  \n",
    "\n",
    "    # Generate predictions for the batch of images\n",
    "    predictions = model.predict(images)  \n",
    "\n",
    "    # Get the predicted class index for each image\n",
    "    pred_labels = tf.argmax(predictions, axis=1)  \n",
    "\n",
    "    # Loop through the first 8 images in the batch\n",
    "    for i in range(8):  \n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))  # Convert and display image\n",
    "        plt.title(f\"True: {class_names[labels[i]]}, Pred: {class_names[pred_labels[i]]}\")  # Show actual and predicted class\n",
    "        plt.axis(\"off\")  # Hide axes for better visualization\n",
    "        plt.show()  # Display the image with title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5dc601-a74b-4053-8c88-9caec6f78f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1ca5ab-b9d2-441a-80e2-dd4d641196e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Efficientnetv2b2.keras')\n",
    "model = tf.keras.models.load_model('Efficientnetv2b2.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f931034-42be-405c-a93b-3b3e6af08e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.applications.efficientnet_v2 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc92ea0e-125a-4e00-9322-389585944010",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_image(img):  \n",
    "\n",
    "    img = img.resize((124, 124))  \n",
    "    img_array = np.array(img, dtype=np.float32)  \n",
    "    img_array = preprocess_input(img_array)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  \n",
    "    prediction = model.predict(img_array)  \n",
    "    predicted_class_index = np.argmax(prediction)  \n",
    "    predicted_class_name = class_names[predicted_class_index]  \n",
    "\n",
    "    confidence = prediction[0][predicted_class_index]  \n",
    "    return f\"Predicted: {predicted_class_name} (Confidence: {confidence:.2f})\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af748c2-2355-43cc-b2c6-3f82dddd6dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "iface = gr.Interface(  \n",
    "    fn=classify_image,  \n",
    "    inputs=gr.Image(type=\"pil\"), \n",
    "    outputs=\"text\" \n",
    ")  \n",
    "\n",
    "\n",
    "iface.launch() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a12966f-3ff1-4f0f-ad50-54b535e85c1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
